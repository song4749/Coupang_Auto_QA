import streamlit as st
from streamlit import runtime
from streamlit.runtime.scriptrunner import get_script_run_ctx
import subprocess
import shutil
import os
import json
import time
from langchain_community.document_loaders import BSHTMLLoader
from langchain_community.vectorstores import FAISS
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.chains.retrieval_qa.base import RetrievalQA
from langchain_core.prompts import PromptTemplate
from dotenv import load_dotenv
import sys

sys.stdout.reconfigure(encoding='utf-8')

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# âœ… HTML íŒŒì¼ì´ ìˆëŠ” í´ë” ê²½ë¡œ
html_folder_path = "ocr_texts"  # ì—¬ëŸ¬ ê°œì˜ HTML íŒŒì¼ì´ ìˆëŠ” í´ë”

# âœ… OpenAI Embeddings ì„¤ì •
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

# ğŸš¨ í¬ë¡¤ë§ ì œí•œ ì„¤ì •
MAX_CRAWL_ATTEMPTS = 3  # ìµœëŒ€ 3ë²ˆ
RESET_TIME = 2 * 60 * 60  # 2ì‹œê°„ (ì´ˆ ë‹¨ìœ„)
CRAWL_LOG_FILE = "user_ip_data.json"  # ì‚¬ìš©ì í¬ë¡¤ë§ ê¸°ë¡ì„ ì €ì¥í•  JSON íŒŒì¼


def get_api_key():
    # í™˜ê²½ ë³€ìˆ˜ ê°€ì ¸ì˜¤ê¸°
    api_key = os.getenv("OPENAI_API_KEY")
    if api_key is None:
        st.error("ğŸš¨ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤! .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
    else:
        st.toast("âœ… OpenAI API í‚¤ê°€ ì •ìƒì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")


# @st.cache_resource
def load_vector_store():
    vectorstore = None  

    # âœ… HTML í´ë” ë‚´ ëª¨ë“  íŒŒì¼ì„ ë‹¤ì‹œ ë²¡í„° DBë¡œ ì €ì¥
    for filename in os.listdir(html_folder_path):
        if filename.endswith(".html"):
            file_path = os.path.join(html_folder_path, filename)
            try:
                # âœ… ê° HTML íŒŒì¼ì„ ê°œë³„ ë¬¸ì„œë¡œ ë¡œë“œ
                loader = BSHTMLLoader(file_path, open_encoding="utf-8", bs_kwargs={"features": "html.parser"})
                documents = loader.load()

                # âœ… ë²¡í„°ìŠ¤í† ì–´ ìƒì„± (ì²« ë²ˆì§¸ ë¬¸ì„œ)
                if vectorstore is None:
                    vectorstore = FAISS.from_documents(documents, embeddings)
                else:
                    vectorstore.add_documents(documents)  # ê¸°ì¡´ DBì— ì¶”ê°€

                print(f"âœ… {filename} ì²˜ë¦¬ ì™„ë£Œ! ({len(documents)}ê°œ ë¬¸ì„œ ì¶”ê°€ë¨)")

                # âœ… HTML íŒŒì¼ ì‚­ì œ
                os.remove(file_path)
                print(f"ğŸ—‘ï¸ {filename} ì‚­ì œ ì™„ë£Œ!")

            except Exception as e:
                print(f"âŒ {filename} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                continue  

    # âœ… ìƒˆë¡œìš´ ë²¡í„° DB ì €ì¥
    if vectorstore:
        vectorstore.save_local("faiss_index")
        print("âœ… ìƒˆë¡œìš´ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì™„ë£Œ!")
        return vectorstore
    else:
        print("âš ï¸ ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì‹¤íŒ¨. HTML íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        return None
        

# âœ… ë²¡í„° DB ì‚­ì œ í•¨ìˆ˜
def delete_vector_db():
    """ë²¡í„° DB ì‚­ì œ í•¨ìˆ˜"""
    if os.path.exists("faiss_index"):
        shutil.rmtree("faiss_index")
        print("ğŸ—‘ ë²¡í„° DB ì‚­ì œ ì™„ë£Œ!")


# âœ… JSON íŒŒì¼ì´ ì—†ìœ¼ë©´ ìë™ ìƒì„±
def initialize_crawl_data():
    if not os.path.exists(CRAWL_LOG_FILE):
        with open(CRAWL_LOG_FILE, "w") as file:
            json.dump({}, file)  # ë¹ˆ JSON ê°ì²´ ìƒì„±
        print(f"ğŸ“‚ {CRAWL_LOG_FILE} íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")


# âœ… JSON íŒŒì¼ì—ì„œ í¬ë¡¤ë§ ë°ì´í„° ë¡œë“œ
def load_crawl_data():
    initialize_crawl_data()  # íŒŒì¼ì´ ì—†ìœ¼ë©´ ìƒì„±
    try:
        with open(CRAWL_LOG_FILE, "r") as file:
            return json.load(file)
    except json.JSONDecodeError:
        print("âš ï¸ JSON íŒŒì¼ì´ ì†ìƒë˜ì—ˆìŠµë‹ˆë‹¤. ì´ˆê¸°í™”í•©ë‹ˆë‹¤.")
        save_crawl_data({})  # ì†ìƒëœ ê²½ìš° ì´ˆê¸°í™”
        return {}


# âœ… JSON íŒŒì¼ì— í¬ë¡¤ë§ ë°ì´í„° ì €ì¥
def save_crawl_data(data):
    with open(CRAWL_LOG_FILE, "w") as file:
        json.dump(data, file, indent=4)


def get_user_ip() -> str:
    """í´ë¼ì´ì–¸íŠ¸(ì‚¬ìš©ì)ì˜ ì‹¤ì œ IP ê°€ì ¸ì˜¤ê¸°"""
    try:
        ctx = get_script_run_ctx()
        if ctx is None:
            return "ì„¸ì…˜ ì—†ìŒ"

        session_info = runtime.get_instance().get_client(ctx.session_id)
        if session_info is None:
            return "í´ë¼ì´ì–¸íŠ¸ ì •ë³´ ì—†ìŒ"
        
        # âœ… í”„ë¡ì‹œ ì„œë²„(Nginx, Caddy) ë’¤ì—ì„œ ì‹¤í–‰ë  ê²½ìš°
        user_ip = session_info.request.headers.get("X-Forwarded-For")
        if user_ip:
            return user_ip.split(",")[0]  # ê°€ì¥ ì•ì˜ IPê°€ ì‹¤ì œ í´ë¼ì´ì–¸íŠ¸ IP
        
        # âœ… ì§ì ‘ ì‹¤í–‰ ì¤‘ì¸ ê²½ìš°
        return session_info.request.remote_ip
    
    except Exception as e:
        return f"ì˜¤ë¥˜ ë°œìƒ: {e}"


# âœ… IPë³„ í¬ë¡¤ë§ íšŸìˆ˜ ê´€ë¦¬
def can_crawl(user_ip):
    crawl_data = load_crawl_data()
    now = time.time()

    # IPë³„ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì´ˆê¸°í™”
    user_data = crawl_data.get(user_ip, {"count": 0, "last_time": now})

    # 2ì‹œê°„ ê²½ê³¼ ì—¬ë¶€ í™•ì¸
    if now - user_data["last_time"] > RESET_TIME:
        user_data["count"] = 0  # í¬ë¡¤ë§ íšŸìˆ˜ ì´ˆê¸°í™”
        user_data["last_time"] = now  # ì‹œê°„ ê°±ì‹ 
        crawl_data[user_ip] = user_data
        save_crawl_data(crawl_data)

    remaining_attempts = MAX_CRAWL_ATTEMPTS - user_data["count"]
    return user_data["count"] < MAX_CRAWL_ATTEMPTS, remaining_attempts  # í¬ë¡¤ë§ ê°€ëŠ¥ ì—¬ë¶€ ë°˜í™˜
    

# âœ… ë²„íŠ¼ í´ë¦­ ì‹œì—ë§Œ í¬ë¡¤ë§ íšŸìˆ˜ ì¦ê°€í•˜ëŠ” í•¨ìˆ˜
def update_crawl_count(user_ip):
    crawl_data = load_crawl_data()
    now = time.time()

    if user_ip in crawl_data:
        crawl_data[user_ip]["count"] += 1  # âœ… ë²„íŠ¼ í´ë¦­ ì‹œì—ë§Œ í¬ë¡¤ë§ íšŸìˆ˜ ì¦ê°€
        crawl_data[user_ip]["last_time"] = now  # ë§ˆì§€ë§‰ í¬ë¡¤ë§ ì‹œê°„ ì—…ë°ì´íŠ¸
    else:
        crawl_data[user_ip] = {"count": 1, "last_time": now}  # ìƒˆ ì‚¬ìš©ì ì¶”ê°€

    save_crawl_data(crawl_data)  # JSON íŒŒì¼ ì €ì¥


# # âœ… Streamlit ì„¸ì…˜ ìƒíƒœ í™•ì¸ ë° ë²¡í„° DB ì‚­ì œ ë¡œì§ ì ìš©
# if "session_active" not in st.session_state:
#     # ğŸš€ ì„¸ì…˜ì´ ìƒˆë¡œ ì‹œì‘ë¨ (ì¦‰, ìƒˆë¡œê³ ì¹¨ ë˜ëŠ” í˜ì´ì§€ ë‹«ê¸° í›„ ë‹¤ì‹œ ì ‘ì†í•œ ê²½ìš°)
#     st.cache_resource.clear()
#     delete_vector_db()  # âœ… ë²¡í„° DB ì‚­ì œ ì‹¤í–‰
    

# # âœ… ì„¸ì…˜ ìƒíƒœì—ì„œ í¬ë¡¤ë§ íšŸìˆ˜ ê´€ë¦¬ (ìµœì´ˆ ì‹¤í–‰ ì‹œ ì´ˆê¸°í™”)
# if "crawl_count" not in st.session_state:
#     st.session_state.crawl_count = 0

# Streamlit UI
st.title("ì¿ íŒ¡ ìë™ì‘ë‹µ ì‹œìŠ¤í…œ")
st.write("ì¿ íŒ¡ ìƒí’ˆ ë§í¬ì™€ ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì‹œë©´ ìë™ìœ¼ë¡œ ë‹µë³€í•´ ë“œë¦½ë‹ˆë‹¤!")
st.warning("âš ï¸ ì£¼ì˜: ì¿ íŒ¡ì—ì„œëŠ” ë™ì¼ IPë¡œ ë°˜ë³µì ì¸ ìš”ì²­ì´ ë°œìƒí•  ê²½ìš°, ì ‘ì†ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê²€ìƒ‰ì€ ìµœëŒ€ 3ë²ˆê¹Œì§€ ê°€ëŠ¥í•˜ë©°, ì´í›„ì—ëŠ” 2ì‹œê°„ì´ ì§€ë‚œ í›„ ë‹¤ì‹œ ì´ìš©í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

initialize_crawl_data()

# ì‚¬ìš©ì IP ê°€ì ¸ì˜¤ê¸°
user_ip = get_user_ip()
st.info(f"ğŸ“Œ í˜„ì¬ ì‚¬ìš©ìì˜ IP: `{user_ip}`")

link = st.text_area("ğŸ”— ìƒí’ˆ íŒë§¤ë§í¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", placeholder="https://www.coupang.com/vp/products/123456...")

# í¬ë¡¤ë§ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
can_crawl_now, remaining_attempts = can_crawl(user_ip)

# âœ… UIì— ë‚¨ì€ í¬ë¡¤ë§ íšŸìˆ˜ë¥¼ í‘œì‹œí•  ê³µê°„ ë§Œë“¤ê¸°
remaining_attempts_display = st.empty()
remaining_attempts_display.write(f"ğŸ”¹ ë‚¨ì€ í¬ë¡¤ë§ íšŸìˆ˜: {remaining_attempts}íšŒ")

if can_crawl_now:
    if st.button("ğŸ–¼ ì´ë¯¸ì§€ í¬ë¡¤ë§ ì‹¤í–‰"):
        if link:
            # âœ… ë²„íŠ¼ì„ í´ë¦­í–ˆì„ ë•Œë§Œ í¬ë¡¤ë§ íšŸìˆ˜ ì¦ê°€
            update_crawl_count(user_ip)

            # âœ… ë‚¨ì€ í¬ë¡¤ë§ íšŸìˆ˜ë¥¼ ì¦‰ì‹œ ì—…ë°ì´íŠ¸
            can_crawl_now, remaining_attempts = can_crawl(user_ip)

            # âœ… ê¸°ì¡´ `st.write()`ë¥¼ ì§€ìš°ê³  ìƒˆë¡œìš´ ê°’ ì¶œë ¥
            remaining_attempts_display.empty()  # ê¸°ì¡´ UI ì‚­ì œ
            remaining_attempts_display.write(f"ğŸ”¹ ë‚¨ì€ í¬ë¡¤ë§ íšŸìˆ˜: {remaining_attempts}íšŒ")

            if remaining_attempts == 0:
                st.error("ğŸš¨ í¬ë¡¤ë§ í—ˆìš© íšŸìˆ˜ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤! 2ì‹œê°„ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

            # âœ… ê¸°ì¡´ ë²¡í„° DB ì‚­ì œ í›„ ì´ˆê¸°í™”
            delete_vector_db()
            st.session_state.vectorstore = None  # ë²¡í„° DB ìºì‹œ ì œê±°

            with st.spinner("ğŸ”„ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
                subprocess.run(["python", "jpg_crowling.py", link], check=True)
            st.toast("âœ… ì´ë¯¸ì§€ í¬ë¡¤ë§ ì™„ë£Œ!")

            with st.spinner("ğŸ”„ ì´ë¯¸ì§€ ë³€í™˜ ì¤‘..."):
                subprocess.run(["python", "jpg2text_run.py"], check=True)
            st.toast("âœ… ë³€í™˜ ì™„ë£Œ! ë°ì´í„°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

            with st.spinner("ğŸ”„ ì •ë³´ ì €ì¥ ì¤‘..."):
                # âœ… OCR ë³€í™˜ëœ HTML íŒŒì¼ì„ ë²¡í„° DBì— ì¶”ê°€
                vectorstore = load_vector_store()

            if vectorstore:
                st.session_state.vectorstore = vectorstore
            else:
                st.error("âš ï¸ ë°ì´í„° ìƒì„± ì‹¤íŒ¨: ë§í¬ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•´ ì£¼ì„¸ìš”.")
            
            # âœ… ë²¡í„° DBê°€ í•„ìš”í•  ê²½ìš° ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
            st.session_state.data_ready = True

            st.toast("âœ… ì €ì¥ ì™„ë£Œ! ì§ˆë¬¸ë°›ì„ ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤.")

        else:
            st.error("âŒ ë§í¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”!")
else:
    # ğŸš¨ í¬ë¡¤ë§ íšŸìˆ˜ ì´ˆê³¼ ì‹œ ê²½ê³  ë©”ì‹œì§€ í‘œì‹œ
    st.error("ğŸš¨ í¬ë¡¤ë§ í—ˆìš© íšŸìˆ˜ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤! 2ì‹œê°„ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

if "data_ready" not in st.session_state:
    st.stop()  # ğŸš€ ì‚¬ìš©ìê°€ ë§í¬ ì…ë ¥ í›„ ì‹¤í–‰ë˜ë„ë¡ ì¤‘ë‹¨

if "api_key_checked" not in st.session_state:
    get_api_key()
    st.session_state.api_key_checked = True


# âœ… ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ
vectorstore = st.session_state.vectorstore if "vectorstore" in st.session_state else load_vector_store()

# âœ… OpenAI LLM (GPT-4 Turbo) ì„¤ì •
llm = ChatOpenAI(model_name="gpt-4o", temperature=0.3)

# âœ… ë¬¸ì„œ ê²€ìƒ‰ì„ ìœ„í•œ Retriever ì„¤ì •
retriever = vectorstore.as_retriever(search_kwargs={"k": 3})  # ê°€ì¥ ê´€ë ¨ ìˆëŠ” 3ê°œ ë¬¸ì„œ ê²€ìƒ‰

# âœ… Prompt í…œí”Œë¦¿ ì„¤ì • (ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ í¬í•¨í•œ ì§ˆì˜ ì‘ë‹µ)
prompt_template = PromptTemplate(
    input_variables=["context", "question"],
    template="""
    ë‹¹ì‹ ì€ ê³ ê° ì§€ì› ì±—ë´‡ì…ë‹ˆë‹¤.  
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì œê³µëœ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.  
    
    âœ… **ë‹µë³€ ë°©ì‹**  
    - ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ìœ¼ë©´, ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ì‰½ê³  ëª…í™•í•˜ê²Œ ì„¤ëª…**í•˜ì„¸ìš”.  
    - ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ, **í•„ìš”í•˜ë©´ ì¶”ê°€ ì„¤ëª…ì„ ë§ë¶™ì´ì„¸ìš”**.  
    - ë„ˆë¬´ ì§§ê±°ë‚˜ ë”±ë”±í•œ ë‹µë³€ ëŒ€ì‹ , **ì¹œì ˆí•˜ê³  ë¶€ë“œëŸ¬ìš´ í†¤ìœ¼ë¡œ ì‘ë‹µ**í•˜ì„¸ìš”.  

    âŒ **ë¬¸ì„œì—ì„œ ë‹µì„ ì°¾ì§€ ëª»í•œ ê²½ìš°**  
    - "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ì •í™•í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.  
    ë³´ë‹¤ ìì„¸í•œ ì‚¬í•­ì€ íŒë§¤ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”." ë¼ê³  ì•ˆë‚´í•˜ì„¸ìš”.  

    ğŸŒŸ **ì¶”ê°€ ì‚¬í•­**  
    - ë¬¸ì„œì— ìˆëŠ” ì •ë³´ë¼ë„ **ë¶ˆí™•ì‹¤í•˜ê±°ë‚˜ ì• ë§¤í•˜ë©´**, í™•ì‹¤í•œ ë¶€ë¶„ë§Œ ë‹µë³€í•˜ì„¸ìš”.  
    - íŒë§¤ì ë¬¸ì˜ë¥¼ ìœ ë„í•  ë•Œ, **ì—°ë½ì²˜ ì •ë³´ê°€ ìˆìœ¼ë©´ í•¨ê»˜ ì œê³µ**í•˜ì„¸ìš”.

    ë¬¸ì„œ ë‚´ìš©:
    {context}

    ì‚¬ìš©ì ì§ˆë¬¸:
    {question}

    ë‹µë³€:
    """,
)

# âœ… RAG ê¸°ë°˜ QA ì‹œìŠ¤í…œ ìƒì„±
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever,
    return_source_documents=False,  # ì°¸ê³ í•œ ë¬¸ì„œë„ í•¨ê»˜ ë°˜í™˜
    chain_type_kwargs={"prompt": prompt_template}
) if retriever else None

user_input = st.text_area("âœï¸ í•´ë‹¹ ìƒí’ˆì— ê´€í•˜ì—¬ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë´ ì£¼ì„¸ìš”", placeholder="ex) ë°°ì†¡ì´ ì–¼ë§ˆë‚˜ ê±¸ë ¤?")

if "answer" not in st.session_state:
    st.session_state.answer = None  # ì²˜ìŒì—ëŠ” ë‹µë³€ ì—†ìŒ

if st.button("ì§ˆë¬¸í•˜ê¸°") and qa_chain:
    if user_input:
        with st.spinner("ğŸ”„ ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘..."):
            response = qa_chain.invoke({"query": user_input})
            st.session_state.answer = response.get("result")
            
        if st.session_state.answer:
            st.markdown(f"ğŸ“Œ **ë‹µë³€:** \n\n{st.session_state.answer}")
    
    else:
        st.error("âŒ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”!")