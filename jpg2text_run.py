import os
import cv2
import numpy as np
import requests
import openai
from datetime import datetime
from dotenv import load_dotenv
from bs4 import BeautifulSoup

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# âœ… í´ë” ê²½ë¡œ ì„¤ì •
save_folder = "download_images"
cropped_folder = "cropped_images"
text_folder = "ocr_texts"

# Upstage Console API ì„¤ì •
API_KEY = os.getenv("API_KEY")
UPLOAD_URL = os.getenv("UPLOAD_URL")

# í™˜ê²½ ë³€ìˆ˜ ê°€ì ¸ì˜¤ê¸°
client = openai.OpenAI(api_key = os.getenv("OPENAI_API_KEY"))
if client is None:
    print("ğŸš¨ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤! .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
else:
    print("âœ… OpenAI API í‚¤ê°€ ì •ìƒì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")


def split_vertical_with_overlap(image_path, output_folder, crop_height=5000, overlap=500):
    """
    ê¸´ ì´ë¯¸ì§€ë¥¼ ì¼ì •í•œ ë†’ì´ë¡œ ë‚˜ëˆ„ë˜, ì¼ì • ë¶€ë¶„ì„ ê²¹ì³ì„œ ìë¥´ëŠ” í•¨ìˆ˜
    - image_path: ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ
    - output_folder: ì €ì¥í•  í´ë”
    - crop_height: ìë¥¼ ë†’ì´ í¬ê¸° (ê¸°ë³¸ê°’: 800px)
    - overlap: ë‹¤ìŒ ì´ë¯¸ì§€ì™€ ê²¹ì¹˜ëŠ” ë¶€ë¶„ (ê¸°ë³¸ê°’: 100px)
    """
    # ì´ë¯¸ì§€ ë¡œë“œ
    image = cv2.imread(image_path)
    if image is None:
        print(f"âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image_path}")
        return []

    # ì´ë¯¸ì§€ í¬ê¸° ê°€ì ¸ì˜¤ê¸°
    height, width, _ = image.shape

    # ì €ì¥í•  í´ë” ìƒì„± (ì—†ìœ¼ë©´ ìƒì„±)
    os.makedirs(output_folder, exist_ok=True)

    count = 0
    y = 0  # ìë¥¼ ìœ„ì¹˜
    base_name = os.path.splitext(os.path.basename(image_path))[0]  # íŒŒì¼ëª… ì¶”ì¶œ
    cropped_image_paths = []

    while y < height:
        # ë§Œì•½ ë‚¨ì€ ë†’ì´ê°€ crop_heightë³´ë‹¤ ì‘ë‹¤ë©´ ë‚¨ì€ ë¶€ë¶„ë§Œ ìë¦„
        if y + crop_height > height:
            cropped = image[y:height, 0:width]  # ë‚¨ì€ ë¶€ë¶„ë§Œ ì €ì¥
        else:
            cropped = image[y:y+crop_height, 0:width]  # ì¼ë°˜ì ì¸ í¬ë¡­

        # í¬ë¡­ëœ ì´ë¯¸ì§€ ì €ì¥ ê²½ë¡œ
        save_path = os.path.join(output_folder, f"{base_name}_crop_{count}.jpg")
        cv2.imwrite(save_path, cropped)
        print(f"âœ… ë¶„í• ëœ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {save_path}")

        cropped_image_paths.append(save_path)  # OCR ìˆ˜í–‰ì„ ìœ„í•´ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
        count += 1

        # ë‹¤ìŒ ìë¥¼ ìœ„ì¹˜ë¥¼ ì¡°ì • (ê²¹ì¹˜ëŠ” ë¶€ë¶„ì„ ë¹¼ê³  ì´ë™)
        y += crop_height - overlap

    print(f"ğŸ“Œ ì´ {count}ê°œì˜ ì´ë¯¸ì§€ë¡œ ë¶„í•  ì™„ë£Œ!")

    os.remove(image_path)
    
    return cropped_image_paths  # ë¶„í• ëœ ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜


def preprocess_image(image_path):
    """OCR ì „ì²˜ë¦¬ë¥¼ ìœ„í•œ ì´ë¯¸ì§€ ë³€í™˜ ë° ë…¸ì´ì¦ˆ ì œê±°"""
    # ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸° (Grayscale ë³€í™˜)
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    
    # ì„ ëª…í•˜ê²Œ í•˜ê¸° (Sharpening)
    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])  # ìƒ¤í”„ë‹ í•„í„°
    img = cv2.filter2D(img, -1, kernel)

    # ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ì €ì¥ (ë””ë²„ê¹…ìš©)
    preprocessed_path = image_path.replace(".jpg", "_processed.jpg").replace(".png", "_processed.png")
    cv2.imwrite(preprocessed_path, img)

    os.remove(image_path)

    return preprocessed_path


def process_ocr_to_html(image_path):
    """ì´ë¯¸ì§€ë¥¼ OCRí•˜ì—¬ HTMLë¡œ ë³€í™˜ í›„ ì €ì¥ (ì¤‘ë³µ ì €ì¥ ë¬¸ì œ í•´ê²°)"""

    # 1ï¸âƒ£ OCR ìˆ˜í–‰ (íŒŒì¼ ì—…ë¡œë“œ)
    with open(image_path, "rb") as image_file:
        files = {"document": image_file}  # âœ… 'document' í‚¤ë¡œ ì „ì†¡
        headers = {"Authorization": f"Bearer {API_KEY}"}
        data = {"ocr": "force", "model": "document-parse"}

        response = requests.post(UPLOAD_URL, headers=headers, files=files, data=data)

        if response.status_code != 200:
            print(f"âŒ Error: {response.status_code}, {response.text}")
            return False

        ocr_data = response.json()

    # 2ï¸âƒ£ HTML ë³€í™˜
    html_content = ocr_data.get("content", {}).get("html", "")

    if not html_content:
        print("âš  OCR ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤! API ì‘ë‹µì„ í™•ì¸í•˜ì„¸ìš”.")
        return False

    # ğŸ“‚ ì €ì¥ í´ë” ìƒì„± (ì—†ìœ¼ë©´ ë§Œë“¤ê¸°)
    os.makedirs(text_folder, exist_ok=True)

    # ğŸ”¥ ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜ íŒŒì¼ëª… ìƒì„±
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    file_name = f"ocr_text_{timestamp}.html"
    output_path = os.path.join(text_folder, file_name)

    # 3ï¸âƒ£ HTML ì €ì¥
    with open(output_path, "w", encoding="utf-8") as file:
        file.write(html_content)

    print(f"âœ… HTML íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}")

    os.remove(image_path)
    
    return True


def merge_and_delete_html_files(html_folder, output_file):
    """ì—¬ëŸ¬ ê°œì˜ HTML íŒŒì¼ì„ í•˜ë‚˜ë¡œ í•©ì¹œ í›„ ê¸°ì¡´ íŒŒì¼ ì‚­ì œ"""
    with open(output_file, 'w', encoding='utf-8') as outfile:
        outfile.write("<!DOCTYPE html>\n<html>\n<head>\n<meta charset='utf-8'>\n<title>Merged HTML</title>\n</head>\n<body>\n")
        
        for file_name in sorted(os.listdir(html_folder)):  # ì •ë ¬ëœ ìˆœì„œë¡œ íŒŒì¼ ì½ê¸°
            if file_name.endswith('.html'):  # .html íŒŒì¼ë§Œ ì²˜ë¦¬
                file_path = os.path.join(html_folder, file_name)
                with open(file_path, 'r', encoding='utf-8') as infile:
                    outfile.write(infile.read())  # HTML ë‚´ìš© ì¶”ê°€
                    outfile.write("\n")  # íŒŒì¼ êµ¬ë¶„ì„ ìœ„í•œ ì¤„ë°”ê¿ˆ ì¶”ê°€
                print(f"âœ… í•©ì¹¨: {file_name}")

        outfile.write("\n</body>\n</html>")  # HTML íƒœê·¸ ë‹«ê¸°

    print(f"ğŸ‰ ëª¨ë“  HTML íŒŒì¼ì´ '{output_file}'ë¡œ í•©ì³ì¡ŒìŠµë‹ˆë‹¤!")

    # âœ… ê¸°ì¡´ HTML íŒŒì¼ ì‚­ì œ
    for file_name in os.listdir(html_folder):
        if file_name.endswith('.html') and file_name != os.path.basename(output_file):
            file_path = os.path.join(html_folder, file_name)
            os.remove(file_path)  # íŒŒì¼ ì‚­ì œ
            print(f"ğŸ—‘ ì‚­ì œ ì™„ë£Œ: {file_name}")

    print("ğŸš€ ê¸°ì¡´ HTML íŒŒì¼ ì‚­ì œ ì™„ë£Œ!")


def clean_html_to_markdown_table(html_content):
    """HTMLì—ì„œ í‘œë¥¼ Markdown í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ê³ , íƒœê·¸ ì†ì„±ì„ ì œê±°í•˜ì—¬ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜"""
    
    # BeautifulSoupìœ¼ë¡œ HTML íŒŒì‹±
    soup = BeautifulSoup(html_content, "html.parser")

    # âœ… <img> íƒœê·¸ì˜ alt ì†ì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    for img in soup.find_all("img"):
        if img.has_attr("alt"):
            img.replace_with(img["alt"])  # ì´ë¯¸ì§€ íƒœê·¸ë¥¼ alt ì†ì„±ê°’ìœ¼ë¡œ ëŒ€ì²´

    # âœ… ëª¨ë“  íƒœê·¸ ì†ì„± ì œê±° (íƒœê·¸ ìì²´ëŠ” ìœ ì§€)
    for tag in soup.find_all(True):
        tag.attrs = {}  # ì†ì„± ì œê±°

    # âœ… <table> íƒœê·¸ë¥¼ Markdown í‘œë¡œ ë³€í™˜
    for table in soup.find_all("table"):
        rows = []
        headers = table.find_all("th")  # í…Œì´ë¸” í—¤ë” ê°€ì ¸ì˜¤ê¸°
        if headers:
            headers_text = [th.get_text(strip=True) for th in headers]
            rows.append("| " + " | ".join(headers_text) + " |")  # Markdown í—¤ë” ì¶”ê°€
            rows.append("|" + "|".join(["-" * len(h) for h in headers_text]) + "|")  # êµ¬ë¶„ì„  ì¶”ê°€

        # ë³¸ë¬¸ ë°ì´í„° ì²˜ë¦¬
        for tr in table.find_all("tr"):
            cols = [td.get_text(strip=True) for td in tr.find_all(["td", "th"])]
            if cols:  # ë¹ˆ í–‰ì´ ì•„ë‹ˆë©´ ì¶”ê°€
                rows.append("| " + " | ".join(cols) + " |")

        table_text = "\n".join(rows)  # Markdown í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        table.replace_with(table_text)  # <table> íƒœê·¸ë¥¼ ë³€í™˜ëœ Markdown í…ìŠ¤íŠ¸ë¡œ ëŒ€ì²´

    # âœ… ìµœì¢…ì ìœ¼ë¡œ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
    clean_text = soup.get_text(separator="\n", strip=True)

    return clean_text


def correct_text_with_openai(input_text):
    """ğŸ“Œ OpenAI API (ìµœì‹  ë²„ì „)ë¡œ RAG ê¸°ë°˜ ê²€ìƒ‰ ìµœì í™” ë¬¸ì„œ ì •ë¦¬"""
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", 
                 "content": 
                 """
                 ì´ ë¬¸ì„œëŠ” RAG ê¸°ë°˜ ê²€ìƒ‰ ë°ì´í„°ë¡œ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤.
                 ë”°ë¼ì„œ ê²€ìƒ‰ ìµœì í™”ë¥¼ ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì´ ì •ë¦¬í•´ ì£¼ì„¸ìš”.

                 1. **ë¬¸ì„œì˜ ì›ë˜ ì˜ë¯¸ë¥¼ ìœ ì§€í•˜ë©´ì„œ ë¬¸ì¥ì„ ë‹¤ë“¬ì–´ ê°€ë…ì„±ì„ ë†’ì´ì„¸ìš”.**  
                 2. **í‘œ(Table) ë°ì´í„°ëŠ” ì›ë³¸ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ì„¸ìš”.** (Markdown í‘œ `|` í˜•ì‹ ìœ ì§€)  
                 3. **ë¶ˆí•„ìš”í•œ ì¤‘ë³µ ë¬¸ì¥ ë° ê³µë°±ì„ ì œê±°í•˜ì„¸ìš”.**  
                 4. **ë¬¸ì„œì˜ ê³„ì¸µ êµ¬ì¡°(ì œëª©, ì†Œì œëª©)ë¥¼ ìœ ì§€í•˜ì—¬ ì‰½ê²Œ ê²€ìƒ‰í•  ìˆ˜ ìˆë„ë¡ í•˜ì„¸ìš”.**   
                 5. **í•„ìš”í•œ ê²½ìš°, ëª©ë¡(Bullet Point)ì„ í™œìš©í•˜ì—¬ ê°€ë…ì„±ì„ ë†’ì´ì„¸ìš”.**  
                 6. **ì˜ë¯¸ë¥¼ ë°”ê¾¸ì§€ ì•Šë„ë¡ ì£¼ì˜í•˜ê³ , ì •ë³´ê°€ ë¹ ì§€ì§€ ì•Šë„ë¡ ìœ ì§€í•˜ì„¸ìš”.**  
                 """
                },
                {"role": "user", "content": input_text}
            ]
        )

        # âœ… ìµœì‹  OpenAI SDKì—ì„œëŠ” ì‘ë‹µ ë°ì´í„° ì ‘ê·¼ ë°©ì‹ ë³€ê²½ë¨
        corrected_text = response.choices[0].message.content

        return corrected_text

    except Exception as e:
        print(f"âŒ OpenAI API ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


def process_text_file(input_folder, output_folder):
    """OCR ê²°ê³¼ íŒŒì¼ì„ ì½ê³  OpenAIë¡œ ìˆ˜ì •í•œ í›„ ë³„ë„ ì €ì¥"""
    for filename in os.listdir(input_folder):
        if filename.endswith(".html"):  # HTML íŒŒì¼ë§Œ ì²˜ë¦¬
            input_path = os.path.join(input_folder, filename)
            output_path = os.path.join(output_folder, filename)

            try:
                with open(input_path, "r", encoding="utf-8") as f:
                    ocr_text = f.read()

                print(f"ğŸš€ OpenAIì— í…ìŠ¤íŠ¸ ì „ë‹¬ ì¤‘... (íŒŒì¼: {input_path})")
                corrected_text = correct_text_with_openai(ocr_text)

                if corrected_text:
                    with open(output_path, "w", encoding="utf-8") as f:
                        f.write(corrected_text)
                    print(f"âœ… ìˆ˜ì •ëœ í…ìŠ¤íŠ¸ ì €ì¥ ì™„ë£Œ: {output_path}")
                else:
                    print(f"âš ï¸ {filename} ì²˜ë¦¬ ì‹¤íŒ¨: OpenAI ì‘ë‹µ ì—†ìŒ")
                    
            except FileNotFoundError:
                print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_path}")


# âœ… OCR ì‹¤í–‰í•  ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ (ì´ë¯¸ ë‹¤ìš´ë¡œë“œëœ ì´ë¯¸ì§€ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°)
image_files = [os.path.join(save_folder, img) for img in os.listdir(save_folder) if img.endswith((".jpg", ".png", ".jpeg"))]

for image_path in image_files:
    print(f"ğŸš€ ì²˜ë¦¬ ì¤‘: {image_path}")

    # 1ï¸âƒ£ ì´ë¯¸ì§€ ì „ì²˜ë¦¬
    processed_image = preprocess_image(image_path)
    if processed_image is None:
        continue  # ì „ì²˜ë¦¬ ì‹¤íŒ¨ ì‹œ ê±´ë„ˆëœ€

    # 2ï¸âƒ£ ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ë¶„í• 
    cropped_images = split_vertical_with_overlap(processed_image, cropped_folder)

    # 3ï¸âƒ£ OCR ìˆ˜í–‰
    for cropped_image in cropped_images:
        # perform_ocr_and_save(cropped_image)
        process_ocr_to_html(cropped_image)

print("ğŸ‰ ëª¨ë“  ì´ë¯¸ì§€ ì²˜ë¦¬ ì™„ë£Œ!")

for filename in os.listdir(text_folder):
        if filename.endswith(".html"):  # HTML íŒŒì¼ë§Œ ì²˜ë¦¬
            input_path = os.path.join(text_folder, filename)
            output_path = os.path.join(text_folder, filename)

            try:
                # âœ… ì›ë³¸ HTML íŒŒì¼ ì½ê¸°
                with open(input_path, "r", encoding="utf-8") as file:
                    html_data = file.read()

                # âœ… HTML ì •ë¦¬ í•¨ìˆ˜ ì‹¤í–‰
                cleaned_html = clean_html_to_markdown_table(html_data)

                # âœ… ì •ë¦¬ëœ HTML ì €ì¥
                with open(output_path, "w", encoding="utf-8") as file:
                    file.write(cleaned_html)

                print(f"âœ… ì •ë¦¬ëœ HTML ì €ì¥ ì™„ë£Œ: {output_path}")

            except FileNotFoundError:
                print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_path}")

process_text_file(text_folder, text_folder)