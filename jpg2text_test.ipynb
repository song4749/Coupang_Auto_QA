{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# import easyocr\n",
    "import cv2\n",
    "import numpy as np\n",
    "import requests\n",
    "# import json\n",
    "# import base64\n",
    "import openai\n",
    "# import pandas as pd\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… í´ë” ê²½ë¡œ ì„¤ì •\n",
    "save_folder = \"download_images\"\n",
    "cropped_folder = \"cropped_images\"\n",
    "text_folder = \"ocr_texts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_vertical_with_overlap(image_path, output_folder, crop_height=5000, overlap=500):\n",
    "    \"\"\"\n",
    "    ê¸´ ì´ë¯¸ì§€ë¥¼ ì¼ì •í•œ ë†’ì´ë¡œ ë‚˜ëˆ„ë˜, ì¼ì • ë¶€ë¶„ì„ ê²¹ì³ì„œ ìë¥´ëŠ” í•¨ìˆ˜\n",
    "    - image_path: ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ\n",
    "    - output_folder: ì €ì¥í•  í´ë”\n",
    "    - crop_height: ìë¥¼ ë†’ì´ í¬ê¸° (ê¸°ë³¸ê°’: 800px)\n",
    "    - overlap: ë‹¤ìŒ ì´ë¯¸ì§€ì™€ ê²¹ì¹˜ëŠ” ë¶€ë¶„ (ê¸°ë³¸ê°’: 100px)\n",
    "    \"\"\"\n",
    "    # ì´ë¯¸ì§€ ë¡œë“œ\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image_path}\")\n",
    "        return []\n",
    "\n",
    "    # ì´ë¯¸ì§€ í¬ê¸° ê°€ì ¸ì˜¤ê¸°\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    # ì €ì¥í•  í´ë” ìƒì„± (ì—†ìœ¼ë©´ ìƒì„±)\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    count = 0\n",
    "    y = 0  # ìë¥¼ ìœ„ì¹˜\n",
    "    base_name = os.path.splitext(os.path.basename(image_path))[0]  # íŒŒì¼ëª… ì¶”ì¶œ\n",
    "    cropped_image_paths = []\n",
    "\n",
    "    while y < height:\n",
    "        # ë§Œì•½ ë‚¨ì€ ë†’ì´ê°€ crop_heightë³´ë‹¤ ì‘ë‹¤ë©´ ë‚¨ì€ ë¶€ë¶„ë§Œ ìë¦„\n",
    "        if y + crop_height > height:\n",
    "            cropped = image[y:height, 0:width]  # ë‚¨ì€ ë¶€ë¶„ë§Œ ì €ì¥\n",
    "        else:\n",
    "            cropped = image[y:y+crop_height, 0:width]  # ì¼ë°˜ì ì¸ í¬ë¡­\n",
    "\n",
    "        # í¬ë¡­ëœ ì´ë¯¸ì§€ ì €ì¥ ê²½ë¡œ\n",
    "        save_path = os.path.join(output_folder, f\"{base_name}_crop_{count}.jpg\")\n",
    "        cv2.imwrite(save_path, cropped)\n",
    "        print(f\"âœ… ë¶„í• ëœ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {save_path}\")\n",
    "\n",
    "        cropped_image_paths.append(save_path)  # OCR ìˆ˜í–‰ì„ ìœ„í•´ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "        count += 1\n",
    "\n",
    "        # ë‹¤ìŒ ìë¥¼ ìœ„ì¹˜ë¥¼ ì¡°ì • (ê²¹ì¹˜ëŠ” ë¶€ë¶„ì„ ë¹¼ê³  ì´ë™)\n",
    "        y += crop_height - overlap\n",
    "\n",
    "    print(f\"ğŸ“Œ ì´ {count}ê°œì˜ ì´ë¯¸ì§€ë¡œ ë¶„í•  ì™„ë£Œ!\")\n",
    "\n",
    "    os.remove(image_path)\n",
    "    \n",
    "    return cropped_image_paths  # ë¶„í• ëœ ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    \"\"\"OCR ì „ì²˜ë¦¬ë¥¼ ìœ„í•œ ì´ë¯¸ì§€ ë³€í™˜ ë° ë…¸ì´ì¦ˆ ì œê±°\"\"\"\n",
    "    # ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸° (Grayscale ë³€í™˜)\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # ì„ ëª…í•˜ê²Œ í•˜ê¸° (Sharpening)\n",
    "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])  # ìƒ¤í”„ë‹ í•„í„°\n",
    "    img = cv2.filter2D(img, -1, kernel)\n",
    "\n",
    "    # ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ì €ì¥ (ë””ë²„ê¹…ìš©)\n",
    "    preprocessed_path = image_path.replace(\".jpg\", \"_processed.jpg\").replace(\".png\", \"_processed.png\")\n",
    "    cv2.imwrite(preprocessed_path, img)\n",
    "\n",
    "    os.remove(image_path)\n",
    "\n",
    "    return preprocessed_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # âœ… OCR ë¦¬ë” ì´ˆê¸°í™” (í•œêµ­ì–´ & ì˜ì–´ ì§€ì›)         # easyocr ì‚¬ìš© - ì„±ëŠ¥ ì•ˆì¢‹ìŒ\n",
    "# reader = easyocr.Reader(['ko', 'en'], gpu=True)\n",
    "\n",
    "# def perform_ocr_and_save(image_path):\n",
    "#     \"\"\"ì´ë¯¸ì§€ì—ì„œ OCR ì‹¤í–‰ í›„ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥\"\"\"\n",
    "#     try:\n",
    "#         # âœ… OCR ì‹¤í–‰\n",
    "#         result = reader.readtext(image_path, detail=0)  # detail=0ì´ë©´ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ\n",
    "#         extracted_text = \"\\n\".join(result)\n",
    "\n",
    "#         # OCR ê²°ê³¼ ì €ì¥ ê²½ë¡œ\n",
    "#         base_name = os.path.basename(image_path).split('.')[0]  # íŒŒì¼ëª… ì¶”ì¶œ (í™•ì¥ì ì œê±°)\n",
    "#         text_file_path = os.path.join(text_folder, f\"{base_name}.txt\")\n",
    "\n",
    "#         # í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥\n",
    "#         with open(text_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#             f.write(extracted_text)\n",
    "\n",
    "#         print(f\"ğŸ“ OCR ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {text_file_path}\")\n",
    "\n",
    "#         os.remove(image_path)\n",
    "\n",
    "#         return text_file_path\n",
    "#     except Exception as e:\n",
    "#         print(f\"âŒ OCR ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "#         return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # âœ… ë„¤ì´ë²„ OCR API ì„¤ì •                  # ë„¤ì´ë²„ ocrì€ í‘œë¥¼ ì¸ì‹ì„ ëª»í•¨\n",
    "# CLOVA_OCR_URL = os.getenv(\"CLOVA_OCR_URL\")\n",
    "# # CLOVA_OCR_URL = \"https://f4zivqekgy.apigw.ntruss.com/custom/v1/38601/4d57efb78176ca8d02304f50749810e755abb9228de0c8c20f105b741fa2cbca/general\"\n",
    "# OCR_SECRET_KEY = os.getenv(\"OCR_SECRET_KEY\")\n",
    "# # OCR_SECRET_KEY = \"UHpBS1RCRERIa1NtSVRWbnJCRWhHeERJRlZoWUNxWnE=\"\n",
    "\n",
    "# HEADERS = {\n",
    "#     \"X-OCR-SECRET\": OCR_SECRET_KEY,  # ë°œê¸‰ë°›ì€ API Key\n",
    "#     \"Content-Type\": \"application/json\"\n",
    "# }\n",
    "\n",
    "\n",
    "# def clova_ocr(image_path):\n",
    "#     \"\"\"ë„¤ì´ë²„ í´ë¡œë°” OCR APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³  í‘œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜\"\"\"\n",
    "#     try:\n",
    "#         # âœ… ì´ë¯¸ì§€ íŒŒì¼ì„ Base64ë¡œ ì¸ì½”ë”©\n",
    "#         with open(image_path, \"rb\") as f:\n",
    "#             image_data = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "#         # âœ… API ìš”ì²­ ë°ì´í„° ì„¤ì •\n",
    "#         payload = {\n",
    "#             \"version\": \"V2\",\n",
    "#             \"requestId\": \"sample_id\",\n",
    "#             \"timestamp\": 123456789,\n",
    "#             \"images\": [{\n",
    "#                 \"format\": \"jpg\",\n",
    "#                 \"name\": \"ocr_test\",\n",
    "#                 \"data\": image_data,\n",
    "#                 \"enableTableDetection\": True,  # í‘œ ê°ì§€ ìš”ì²­\n",
    "#                 \"detectOrientation\": True\n",
    "#             }]\n",
    "#         }\n",
    "\n",
    "#         # âœ… ë„¤ì´ë²„ OCR API í˜¸ì¶œ\n",
    "#         response = requests.post(CLOVA_OCR_URL, headers=HEADERS, data=json.dumps(payload))\n",
    "\n",
    "#         # âœ… ì‘ë‹µ ìƒíƒœ ì½”ë“œ í™•ì¸\n",
    "#         if response.status_code != 200:\n",
    "#             print(f\"âŒ ë„¤ì´ë²„ OCR API ì˜¤ë¥˜: {response.text}\")\n",
    "#             return None\n",
    "\n",
    "#         # âœ… ì‘ë‹µì„ JSONìœ¼ë¡œ ë³€í™˜\n",
    "#         result = response.json()\n",
    "\n",
    "#         # âœ… OCR ê²°ê³¼ ì¶”ì¶œ ë° í‘œ ë³€í™˜\n",
    "#         extracted_text = []\n",
    "#         if \"images\" in result:\n",
    "#             for image in result.get(\"images\", []):\n",
    "#                 for field in image.get(\"fields\", []):\n",
    "#                     extracted_text.append(field.get(\"inferText\", \"\"))\n",
    "\n",
    "#         # âœ… OCR ê²°ê³¼ë¥¼ ë²”ìš©ì ì¸ í‘œ ë°ì´í„°ë¡œ ë³€í™˜\n",
    "#         table_data = reconstruct_table_from_text(extracted_text)\n",
    "\n",
    "#         # âœ… JSON í˜•ì‹ìœ¼ë¡œ OCR ê²°ê³¼ ì €ì¥\n",
    "#         base_name = os.path.basename(image_path).split('.')[0]\n",
    "#         os.makedirs(\"ocr_results\", exist_ok=True)\n",
    "#         json_file_path = os.path.join(\"ocr_results\", f\"{base_name}.json\")\n",
    "\n",
    "#         ocr_result = {\n",
    "#             \"text\": extracted_text,\n",
    "#             \"table\": table_data\n",
    "#         }\n",
    "\n",
    "#         with open(json_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#             json.dump(ocr_result, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "#         print(f\"ğŸ“ OCR JSON ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {json_file_path}\")\n",
    "\n",
    "#         return {\"json_file\": json_file_path, \"table_data\": table_data}\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"âŒ ë„¤ì´ë²„ OCR ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "#         return None\n",
    "\n",
    "\n",
    "# def reconstruct_table_from_text(text_blocks):\n",
    "#     \"\"\"OCRì—ì„œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ë²”ìš©ì ì¸ í‘œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜\"\"\"\n",
    "#     table_data = []\n",
    "#     row = []\n",
    "    \n",
    "#     for word in text_blocks:\n",
    "#         if word.isdigit():  # ìˆ«ìê°€ ë‚˜ì˜¤ë©´ ì—´ì´ ëë‚¬ë‹¤ê³  ê°€ì •\n",
    "#             row.append(word)\n",
    "#             table_data.append(row)\n",
    "#             row = []\n",
    "#         else:\n",
    "#             row.append(word)\n",
    "\n",
    "#     # ë§ˆì§€ë§‰ ì¤„ ì¶”ê°€ (í˜¹ì‹œ ë¹ ì§„ ê²½ìš°)\n",
    "#     if row:\n",
    "#         table_data.append(row)\n",
    "\n",
    "#     return table_data\n",
    "\n",
    "\n",
    "# def format_table_for_openai(table_data):\n",
    "#     \"\"\"OpenAIê°€ í‘œë¡œ ì¸ì‹í•  ìˆ˜ ìˆë„ë¡ Markdown í˜•ì‹ìœ¼ë¡œ ë³€í™˜\"\"\"\n",
    "#     if not table_data:\n",
    "#         return \"âš  í‘œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "#     # í—¤ë”ì™€ êµ¬ë¶„ì„  ìƒì„±\n",
    "#     header = \"| \" + \" | \".join(table_data[0]) + \" |\"\n",
    "#     separator = \"| \" + \" | \".join([\"---\"] * len(table_data[0])) + \" |\"\n",
    "\n",
    "#     markdown_table = [header, separator]\n",
    "\n",
    "#     # ë°ì´í„° í–‰ ì¶”ê°€\n",
    "#     for row in table_data[1:]:\n",
    "#         markdown_table.append(\"| \" + \" | \".join(row) + \" |\")\n",
    "\n",
    "#     return \"\\n\".join(markdown_table)\n",
    "\n",
    "# # ğŸ“Œ ì˜ˆì œ ì‹¤í–‰\n",
    "# if __name__ == \"__main__\":\n",
    "#     image_path = \"aasdaf.JPG\"\n",
    "#     result = clova_ocr(image_path)\n",
    "#     if result and \"table_data\" in result:\n",
    "#         markdown_table = format_table_for_openai(result[\"table_data\"])\n",
    "#         print(\"\\nğŸ“Œ ë³€í™˜ëœ í‘œ ë°ì´í„° (Markdown í˜•ì‹)\\n\")\n",
    "#         print(markdown_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upstage Console API ì„¤ì •\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "UPLOAD_URL = os.getenv(\"UPLOAD_URL\")\n",
    "\n",
    "\n",
    "def process_ocr_to_html(image_path):\n",
    "    \"\"\"ì´ë¯¸ì§€ë¥¼ OCRí•˜ì—¬ HTMLë¡œ ë³€í™˜ í›„ ì €ì¥ (ì¤‘ë³µ ì €ì¥ ë¬¸ì œ í•´ê²°)\"\"\"\n",
    "\n",
    "    # 1ï¸âƒ£ OCR ìˆ˜í–‰ (íŒŒì¼ ì—…ë¡œë“œ)\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        files = {\"document\": image_file}  # âœ… 'document' í‚¤ë¡œ ì „ì†¡\n",
    "        headers = {\"Authorization\": f\"Bearer {API_KEY}\"}\n",
    "        data = {\"ocr\": \"force\", \"model\": \"document-parse\"}\n",
    "\n",
    "        response = requests.post(UPLOAD_URL, headers=headers, files=files, data=data)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(f\"âŒ Error: {response.status_code}, {response.text}\")\n",
    "            return False\n",
    "\n",
    "        ocr_data = response.json()\n",
    "\n",
    "    # 2ï¸âƒ£ HTML ë³€í™˜\n",
    "    html_content = ocr_data.get(\"content\", {}).get(\"html\", \"\")\n",
    "\n",
    "    if not html_content:\n",
    "        print(\"âš  OCR ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤! API ì‘ë‹µì„ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "        return False\n",
    "\n",
    "    # ğŸ“‚ ì €ì¥ í´ë” ìƒì„± (ì—†ìœ¼ë©´ ë§Œë“¤ê¸°)\n",
    "    os.makedirs(text_folder, exist_ok=True)\n",
    "\n",
    "    # ğŸ”¥ ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜ íŒŒì¼ëª… ìƒì„±\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    file_name = f\"ocr_text_{timestamp}.html\"\n",
    "    output_path = os.path.join(text_folder, file_name)\n",
    "\n",
    "    # 3ï¸âƒ£ HTML ì €ì¥\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(html_content)\n",
    "\n",
    "    print(f\"âœ… HTML íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}\")\n",
    "\n",
    "    os.remove(image_path)\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_and_delete_html_files(html_folder, output_file):\n",
    "    \"\"\"ì—¬ëŸ¬ ê°œì˜ HTML íŒŒì¼ì„ í•˜ë‚˜ë¡œ í•©ì¹œ í›„ ê¸°ì¡´ íŒŒì¼ ì‚­ì œ\"\"\"\n",
    "    with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        outfile.write(\"<!DOCTYPE html>\\n<html>\\n<head>\\n<meta charset='utf-8'>\\n<title>Merged HTML</title>\\n</head>\\n<body>\\n\")\n",
    "        \n",
    "        for file_name in sorted(os.listdir(html_folder)):  # ì •ë ¬ëœ ìˆœì„œë¡œ íŒŒì¼ ì½ê¸°\n",
    "            if file_name.endswith('.html'):  # .html íŒŒì¼ë§Œ ì²˜ë¦¬\n",
    "                file_path = os.path.join(html_folder, file_name)\n",
    "                with open(file_path, 'r', encoding='utf-8') as infile:\n",
    "                    outfile.write(infile.read())  # HTML ë‚´ìš© ì¶”ê°€\n",
    "                    outfile.write(\"\\n\")  # íŒŒì¼ êµ¬ë¶„ì„ ìœ„í•œ ì¤„ë°”ê¿ˆ ì¶”ê°€\n",
    "                print(f\"âœ… í•©ì¹¨: {file_name}\")\n",
    "\n",
    "        outfile.write(\"\\n</body>\\n</html>\")  # HTML íƒœê·¸ ë‹«ê¸°\n",
    "\n",
    "    print(f\"ğŸ‰ ëª¨ë“  HTML íŒŒì¼ì´ '{output_file}'ë¡œ í•©ì³ì¡ŒìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "    # âœ… ê¸°ì¡´ HTML íŒŒì¼ ì‚­ì œ\n",
    "    for file_name in os.listdir(html_folder):\n",
    "        if file_name.endswith('.html') and file_name != os.path.basename(output_file):\n",
    "            file_path = os.path.join(html_folder, file_name)\n",
    "            os.remove(file_path)  # íŒŒì¼ ì‚­ì œ\n",
    "            print(f\"ğŸ—‘ ì‚­ì œ ì™„ë£Œ: {file_name}\")\n",
    "\n",
    "    print(\"ğŸš€ ê¸°ì¡´ HTML íŒŒì¼ ì‚­ì œ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_html_to_markdown_table(html_content):\n",
    "    \"\"\"HTMLì—ì„œ í‘œë¥¼ Markdown í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ê³ , íƒœê·¸ ì†ì„±ì„ ì œê±°í•˜ì—¬ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    \n",
    "    # BeautifulSoupìœ¼ë¡œ HTML íŒŒì‹±\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "    # âœ… <img> íƒœê·¸ì˜ alt ì†ì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "    for img in soup.find_all(\"img\"):\n",
    "        if img.has_attr(\"alt\"):\n",
    "            img.replace_with(img[\"alt\"])  # ì´ë¯¸ì§€ íƒœê·¸ë¥¼ alt ì†ì„±ê°’ìœ¼ë¡œ ëŒ€ì²´\n",
    "\n",
    "    # âœ… ëª¨ë“  íƒœê·¸ ì†ì„± ì œê±° (íƒœê·¸ ìì²´ëŠ” ìœ ì§€)\n",
    "    for tag in soup.find_all(True):\n",
    "        tag.attrs = {}  # ì†ì„± ì œê±°\n",
    "\n",
    "    # âœ… <table> íƒœê·¸ë¥¼ Markdown í‘œë¡œ ë³€í™˜\n",
    "    for table in soup.find_all(\"table\"):\n",
    "        rows = []\n",
    "        headers = table.find_all(\"th\")  # í…Œì´ë¸” í—¤ë” ê°€ì ¸ì˜¤ê¸°\n",
    "        if headers:\n",
    "            headers_text = [th.get_text(strip=True) for th in headers]\n",
    "            rows.append(\"| \" + \" | \".join(headers_text) + \" |\")  # Markdown í—¤ë” ì¶”ê°€\n",
    "            rows.append(\"|\" + \"|\".join([\"-\" * len(h) for h in headers_text]) + \"|\")  # êµ¬ë¶„ì„  ì¶”ê°€\n",
    "\n",
    "        # ë³¸ë¬¸ ë°ì´í„° ì²˜ë¦¬\n",
    "        for tr in table.find_all(\"tr\"):\n",
    "            cols = [td.get_text(strip=True) for td in tr.find_all([\"td\", \"th\"])]\n",
    "            if cols:  # ë¹ˆ í–‰ì´ ì•„ë‹ˆë©´ ì¶”ê°€\n",
    "                rows.append(\"| \" + \" | \".join(cols) + \" |\")\n",
    "\n",
    "        table_text = \"\\n\".join(rows)  # Markdown í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "        table.replace_with(table_text)  # <table> íƒœê·¸ë¥¼ ë³€í™˜ëœ Markdown í…ìŠ¤íŠ¸ë¡œ ëŒ€ì²´\n",
    "\n",
    "    # âœ… ìµœì¢…ì ìœ¼ë¡œ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ\n",
    "    clean_text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ì²˜ë¦¬ ì¤‘: download_images\\image_1.jpg\n",
      "âœ… ë¶„í• ëœ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: cropped_images\\image_1_processed_crop_0.jpg\n",
      "ğŸ“Œ ì´ 1ê°œì˜ ì´ë¯¸ì§€ë¡œ ë¶„í•  ì™„ë£Œ!\n",
      "âœ… HTML íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: ocr_texts\\ocr_text_20250221_162052.html\n",
      "ğŸš€ ì²˜ë¦¬ ì¤‘: download_images\\image_2.jpg\n",
      "âœ… ë¶„í• ëœ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: cropped_images\\image_2_processed_crop_0.jpg\n",
      "ğŸ“Œ ì´ 1ê°œì˜ ì´ë¯¸ì§€ë¡œ ë¶„í•  ì™„ë£Œ!\n",
      "âœ… HTML íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: ocr_texts\\ocr_text_20250221_162053.html\n",
      "ğŸš€ ì²˜ë¦¬ ì¤‘: download_images\\image_3.jpg\n",
      "âœ… ë¶„í• ëœ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: cropped_images\\image_3_processed_crop_0.jpg\n",
      "âœ… ë¶„í• ëœ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: cropped_images\\image_3_processed_crop_1.jpg\n",
      "âœ… ë¶„í• ëœ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: cropped_images\\image_3_processed_crop_2.jpg\n",
      "ğŸ“Œ ì´ 3ê°œì˜ ì´ë¯¸ì§€ë¡œ ë¶„í•  ì™„ë£Œ!\n",
      "âœ… HTML íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: ocr_texts\\ocr_text_20250221_162055.html\n",
      "âœ… HTML íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: ocr_texts\\ocr_text_20250221_162057.html\n",
      "âœ… HTML íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: ocr_texts\\ocr_text_20250221_162058.html\n",
      "ğŸš€ ì²˜ë¦¬ ì¤‘: download_images\\image_4.png\n",
      "âœ… ë¶„í• ëœ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: cropped_images\\image_4_processed_crop_0.jpg\n",
      "ğŸ“Œ ì´ 1ê°œì˜ ì´ë¯¸ì§€ë¡œ ë¶„í•  ì™„ë£Œ!\n",
      "âœ… HTML íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: ocr_texts\\ocr_text_20250221_162100.html\n",
      "ğŸ‰ ëª¨ë“  ì´ë¯¸ì§€ ì²˜ë¦¬ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# âœ… OCR ì‹¤í–‰í•  ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ (ì´ë¯¸ ë‹¤ìš´ë¡œë“œëœ ì´ë¯¸ì§€ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°)\n",
    "image_files = [os.path.join(save_folder, img) for img in os.listdir(save_folder) if img.endswith((\".jpg\", \".png\", \".jpeg\"))]\n",
    "\n",
    "\n",
    "for image_path in image_files:\n",
    "    print(f\"ğŸš€ ì²˜ë¦¬ ì¤‘: {image_path}\")\n",
    "\n",
    "    # 1ï¸âƒ£ ì´ë¯¸ì§€ ì „ì²˜ë¦¬\n",
    "    processed_image = preprocess_image(image_path)\n",
    "    if processed_image is None:\n",
    "        continue  # ì „ì²˜ë¦¬ ì‹¤íŒ¨ ì‹œ ê±´ë„ˆëœ€\n",
    "\n",
    "    # 2ï¸âƒ£ ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ë¶„í• \n",
    "    cropped_images = split_vertical_with_overlap(processed_image, cropped_folder)\n",
    "\n",
    "    # 3ï¸âƒ£ OCR ìˆ˜í–‰\n",
    "    for cropped_image in cropped_images:\n",
    "        # perform_ocr_and_save(cropped_image)\n",
    "        process_ocr_to_html(cropped_image)\n",
    "\n",
    "print(\"ğŸ‰ ëª¨ë“  ì´ë¯¸ì§€ ì²˜ë¦¬ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì •ë¦¬ëœ HTML ì €ì¥ ì™„ë£Œ: ocr_texts\\ocr_text_20250221_162052.html\n",
      "âœ… ì •ë¦¬ëœ HTML ì €ì¥ ì™„ë£Œ: ocr_texts\\ocr_text_20250221_162053.html\n",
      "âœ… ì •ë¦¬ëœ HTML ì €ì¥ ì™„ë£Œ: ocr_texts\\ocr_text_20250221_162055.html\n",
      "âœ… ì •ë¦¬ëœ HTML ì €ì¥ ì™„ë£Œ: ocr_texts\\ocr_text_20250221_162057.html\n",
      "âœ… ì •ë¦¬ëœ HTML ì €ì¥ ì™„ë£Œ: ocr_texts\\ocr_text_20250221_162058.html\n",
      "âœ… ì •ë¦¬ëœ HTML ì €ì¥ ì™„ë£Œ: ocr_texts\\ocr_text_20250221_162100.html\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(text_folder):\n",
    "        if filename.endswith(\".html\"):  # HTML íŒŒì¼ë§Œ ì²˜ë¦¬\n",
    "            input_path = os.path.join(text_folder, filename)\n",
    "            output_path = os.path.join(text_folder, filename)\n",
    "\n",
    "            try:\n",
    "                # âœ… ì›ë³¸ HTML íŒŒì¼ ì½ê¸°\n",
    "                with open(input_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                    html_data = file.read()\n",
    "\n",
    "                # âœ… HTML ì •ë¦¬ í•¨ìˆ˜ ì‹¤í–‰\n",
    "                cleaned_html = clean_html_to_markdown_table(html_data)\n",
    "\n",
    "                # âœ… ì •ë¦¬ëœ HTML ì €ì¥\n",
    "                with open(output_path, \"w\", encoding=\"utf-8\") as file:\n",
    "                    file.write(cleaned_html)\n",
    "\n",
    "                print(f\"âœ… ì •ë¦¬ëœ HTML ì €ì¥ ì™„ë£Œ: {output_path}\")\n",
    "\n",
    "            except FileNotFoundError:\n",
    "                print(f\"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… OpenAI API í‚¤ê°€ ì •ìƒì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# í™˜ê²½ ë³€ìˆ˜ ê°€ì ¸ì˜¤ê¸°\n",
    "client = openai.OpenAI(api_key = os.getenv(\"OPENAI_API_KEY\"))\n",
    "if client is None:\n",
    "    print(\"ğŸš¨ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤! .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "else:\n",
    "    print(\"âœ… OpenAI API í‚¤ê°€ ì •ìƒì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_text_with_openai(input_text):\n",
    "    \"\"\"ğŸ“Œ OpenAI API (ìµœì‹  ë²„ì „)ë¡œ RAG ê¸°ë°˜ ê²€ìƒ‰ ìµœì í™” ë¬¸ì„œ ì •ë¦¬\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \n",
    "                 \"content\": \n",
    "                 \"\"\"\n",
    "                 ì´ ë¬¸ì„œëŠ” RAG ê¸°ë°˜ ê²€ìƒ‰ ë°ì´í„°ë¡œ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤.\n",
    "                 ë”°ë¼ì„œ ê²€ìƒ‰ ìµœì í™”ë¥¼ ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì´ ì •ë¦¬í•´ ì£¼ì„¸ìš”.\n",
    "\n",
    "                 1. **ë¬¸ì„œì˜ ì›ë˜ ì˜ë¯¸ë¥¼ ìœ ì§€í•˜ë©´ì„œ ë¬¸ì¥ì„ ë‹¤ë“¬ì–´ ê°€ë…ì„±ì„ ë†’ì´ì„¸ìš”.**  \n",
    "                 2. **í‘œ(Table) ë°ì´í„°ëŠ” ì›ë³¸ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ì„¸ìš”.** (Markdown í‘œ `|` í˜•ì‹ ìœ ì§€)  \n",
    "                 3. **ë¶ˆí•„ìš”í•œ ì¤‘ë³µ ë¬¸ì¥ ë° ê³µë°±ì„ ì œê±°í•˜ì„¸ìš”.**  \n",
    "                 4. **ë¬¸ì„œì˜ ê³„ì¸µ êµ¬ì¡°(ì œëª©, ì†Œì œëª©)ë¥¼ ìœ ì§€í•˜ì—¬ ì‰½ê²Œ ê²€ìƒ‰í•  ìˆ˜ ìˆë„ë¡ í•˜ì„¸ìš”.**   \n",
    "                 5. **í•„ìš”í•œ ê²½ìš°, ëª©ë¡(Bullet Point)ì„ í™œìš©í•˜ì—¬ ê°€ë…ì„±ì„ ë†’ì´ì„¸ìš”.**  \n",
    "                 6. **ì˜ë¯¸ë¥¼ ë°”ê¾¸ì§€ ì•Šë„ë¡ ì£¼ì˜í•˜ê³ , ì •ë³´ê°€ ë¹ ì§€ì§€ ì•Šë„ë¡ ìœ ì§€í•˜ì„¸ìš”.**  \n",
    "                 \"\"\"\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": input_text}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # âœ… ìµœì‹  OpenAI SDKì—ì„œëŠ” ì‘ë‹µ ë°ì´í„° ì ‘ê·¼ ë°©ì‹ ë³€ê²½ë¨\n",
    "        corrected_text = response.choices[0].message.content\n",
    "\n",
    "        return corrected_text\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ OpenAI API ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text_file(input_folder, output_folder):\n",
    "    \"\"\"OCR ê²°ê³¼ íŒŒì¼ì„ ì½ê³  OpenAIë¡œ ìˆ˜ì •í•œ í›„ ë³„ë„ ì €ì¥\"\"\"\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".html\"):  # HTML íŒŒì¼ë§Œ ì²˜ë¦¬\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "            output_path = os.path.join(output_folder, filename)\n",
    "\n",
    "            try:\n",
    "                with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    ocr_text = f.read()\n",
    "\n",
    "                print(f\"ğŸš€ OpenAIì— í…ìŠ¤íŠ¸ ì „ë‹¬ ì¤‘... (íŒŒì¼: {input_path})\")\n",
    "                corrected_text = correct_text_with_openai(ocr_text)\n",
    "\n",
    "                if corrected_text:\n",
    "                    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                        f.write(corrected_text)\n",
    "                    print(f\"âœ… ìˆ˜ì •ëœ í…ìŠ¤íŠ¸ ì €ì¥ ì™„ë£Œ: {output_path}\")\n",
    "                else:\n",
    "                    print(f\"âš ï¸ {filename} ì²˜ë¦¬ ì‹¤íŒ¨: OpenAI ì‘ë‹µ ì—†ìŒ\")\n",
    "                    \n",
    "            except FileNotFoundError:\n",
    "                print(f\"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ OpenAIì— í…ìŠ¤íŠ¸ ì „ë‹¬ ì¤‘... (íŒŒì¼: ocr_texts\\ocr_text_20250221_162052.html)\n",
      "âœ… ìˆ˜ì •ëœ í…ìŠ¤íŠ¸ ì €ì¥ ì™„ë£Œ: ocr_texts\\ocr_text_20250221_162052.html\n",
      "ğŸš€ OpenAIì— í…ìŠ¤íŠ¸ ì „ë‹¬ ì¤‘... (íŒŒì¼: ocr_texts\\ocr_text_20250221_162053.html)\n",
      "âœ… ìˆ˜ì •ëœ í…ìŠ¤íŠ¸ ì €ì¥ ì™„ë£Œ: ocr_texts\\ocr_text_20250221_162053.html\n",
      "ğŸš€ OpenAIì— í…ìŠ¤íŠ¸ ì „ë‹¬ ì¤‘... (íŒŒì¼: ocr_texts\\ocr_text_20250221_162055.html)\n",
      "âœ… ìˆ˜ì •ëœ í…ìŠ¤íŠ¸ ì €ì¥ ì™„ë£Œ: ocr_texts\\ocr_text_20250221_162055.html\n",
      "ğŸš€ OpenAIì— í…ìŠ¤íŠ¸ ì „ë‹¬ ì¤‘... (íŒŒì¼: ocr_texts\\ocr_text_20250221_162057.html)\n",
      "âœ… ìˆ˜ì •ëœ í…ìŠ¤íŠ¸ ì €ì¥ ì™„ë£Œ: ocr_texts\\ocr_text_20250221_162057.html\n",
      "ğŸš€ OpenAIì— í…ìŠ¤íŠ¸ ì „ë‹¬ ì¤‘... (íŒŒì¼: ocr_texts\\ocr_text_20250221_162058.html)\n",
      "âœ… ìˆ˜ì •ëœ í…ìŠ¤íŠ¸ ì €ì¥ ì™„ë£Œ: ocr_texts\\ocr_text_20250221_162058.html\n",
      "ğŸš€ OpenAIì— í…ìŠ¤íŠ¸ ì „ë‹¬ ì¤‘... (íŒŒì¼: ocr_texts\\ocr_text_20250221_162100.html)\n",
      "âœ… ìˆ˜ì •ëœ í…ìŠ¤íŠ¸ ì €ì¥ ì™„ë£Œ: ocr_texts\\ocr_text_20250221_162100.html\n"
     ]
    }
   ],
   "source": [
    "process_text_file(text_folder, text_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # âœ… ì‚¬ìš© ì˜ˆì‹œ (í´ë” ê²½ë¡œ ì„¤ì •)\n",
    "# output_file = os.path.join(text_folder, \"merged_text.html\")  # ìµœì¢… í•©ì³ì§ˆ íŒŒì¼ ê²½ë¡œ\n",
    "\n",
    "# merge_and_delete_html_files(text_folder, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
