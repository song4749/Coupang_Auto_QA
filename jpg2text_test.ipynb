{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# import easyocr\n",
    "import cv2\n",
    "import numpy as np\n",
    "import requests\n",
    "# import json\n",
    "# import base64\n",
    "import openai\n",
    "# import pandas as pd\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# .env 파일에서 환경 변수 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 폴더 경로 설정\n",
    "save_folder = \"download_images\"\n",
    "cropped_folder = \"cropped_images\"\n",
    "text_folder = \"ocr_texts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_vertical_with_overlap(image_path, output_folder, crop_height=5000, overlap=500):\n",
    "    \"\"\"\n",
    "    긴 이미지를 일정한 높이로 나누되, 일정 부분을 겹쳐서 자르는 함수\n",
    "    - image_path: 원본 이미지 경로\n",
    "    - output_folder: 저장할 폴더\n",
    "    - crop_height: 자를 높이 크기 (기본값: 800px)\n",
    "    - overlap: 다음 이미지와 겹치는 부분 (기본값: 100px)\n",
    "    \"\"\"\n",
    "    # 이미지 로드\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"❌ 이미지 로드 실패: {image_path}\")\n",
    "        return []\n",
    "\n",
    "    # 이미지 크기 가져오기\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    # 저장할 폴더 생성 (없으면 생성)\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    count = 0\n",
    "    y = 0  # 자를 위치\n",
    "    base_name = os.path.splitext(os.path.basename(image_path))[0]  # 파일명 추출\n",
    "    cropped_image_paths = []\n",
    "\n",
    "    while y < height:\n",
    "        # 만약 남은 높이가 crop_height보다 작다면 남은 부분만 자름\n",
    "        if y + crop_height > height:\n",
    "            cropped = image[y:height, 0:width]  # 남은 부분만 저장\n",
    "        else:\n",
    "            cropped = image[y:y+crop_height, 0:width]  # 일반적인 크롭\n",
    "\n",
    "        # 크롭된 이미지 저장 경로\n",
    "        save_path = os.path.join(output_folder, f\"{base_name}_crop_{count}.jpg\")\n",
    "        cv2.imwrite(save_path, cropped)\n",
    "        print(f\"✅ 분할된 이미지 저장 완료: {save_path}\")\n",
    "\n",
    "        cropped_image_paths.append(save_path)  # OCR 수행을 위해 리스트에 추가\n",
    "        count += 1\n",
    "\n",
    "        # 다음 자를 위치를 조정 (겹치는 부분을 빼고 이동)\n",
    "        y += crop_height - overlap\n",
    "\n",
    "    print(f\"📌 총 {count}개의 이미지로 분할 완료!\")\n",
    "\n",
    "    os.remove(image_path)\n",
    "    \n",
    "    return cropped_image_paths  # 분할된 이미지 경로 리스트 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    \"\"\"OCR 전처리를 위한 이미지 변환 및 노이즈 제거\"\"\"\n",
    "    # 이미지 불러오기 (Grayscale 변환)\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # 선명하게 하기 (Sharpening)\n",
    "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])  # 샤프닝 필터\n",
    "    img = cv2.filter2D(img, -1, kernel)\n",
    "\n",
    "    # 전처리된 이미지 저장 (디버깅용)\n",
    "    preprocessed_path = image_path.replace(\".jpg\", \"_processed.jpg\").replace(\".png\", \"_processed.png\")\n",
    "    cv2.imwrite(preprocessed_path, img)\n",
    "\n",
    "    os.remove(image_path)\n",
    "\n",
    "    return preprocessed_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ✅ OCR 리더 초기화 (한국어 & 영어 지원)         # easyocr 사용 - 성능 안좋음\n",
    "# reader = easyocr.Reader(['ko', 'en'], gpu=True)\n",
    "\n",
    "# def perform_ocr_and_save(image_path):\n",
    "#     \"\"\"이미지에서 OCR 실행 후 결과를 텍스트 파일로 저장\"\"\"\n",
    "#     try:\n",
    "#         # ✅ OCR 실행\n",
    "#         result = reader.readtext(image_path, detail=0)  # detail=0이면 텍스트만 추출\n",
    "#         extracted_text = \"\\n\".join(result)\n",
    "\n",
    "#         # OCR 결과 저장 경로\n",
    "#         base_name = os.path.basename(image_path).split('.')[0]  # 파일명 추출 (확장자 제거)\n",
    "#         text_file_path = os.path.join(text_folder, f\"{base_name}.txt\")\n",
    "\n",
    "#         # 텍스트 파일로 저장\n",
    "#         with open(text_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#             f.write(extracted_text)\n",
    "\n",
    "#         print(f\"📝 OCR 결과 저장 완료: {text_file_path}\")\n",
    "\n",
    "#         os.remove(image_path)\n",
    "\n",
    "#         return text_file_path\n",
    "#     except Exception as e:\n",
    "#         print(f\"❌ OCR 처리 중 오류 발생: {e}\")\n",
    "#         return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ✅ 네이버 OCR API 설정                  # 네이버 ocr은 표를 인식을 못함\n",
    "# CLOVA_OCR_URL = os.getenv(\"CLOVA_OCR_URL\")\n",
    "# # CLOVA_OCR_URL = \"https://f4zivqekgy.apigw.ntruss.com/custom/v1/38601/4d57efb78176ca8d02304f50749810e755abb9228de0c8c20f105b741fa2cbca/general\"\n",
    "# OCR_SECRET_KEY = os.getenv(\"OCR_SECRET_KEY\")\n",
    "# # OCR_SECRET_KEY = \"UHpBS1RCRERIa1NtSVRWbnJCRWhHeERJRlZoWUNxWnE=\"\n",
    "\n",
    "# HEADERS = {\n",
    "#     \"X-OCR-SECRET\": OCR_SECRET_KEY,  # 발급받은 API Key\n",
    "#     \"Content-Type\": \"application/json\"\n",
    "# }\n",
    "\n",
    "\n",
    "# def clova_ocr(image_path):\n",
    "#     \"\"\"네이버 클로바 OCR API를 사용하여 이미지에서 텍스트를 추출하고 표 형식으로 변환\"\"\"\n",
    "#     try:\n",
    "#         # ✅ 이미지 파일을 Base64로 인코딩\n",
    "#         with open(image_path, \"rb\") as f:\n",
    "#             image_data = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "#         # ✅ API 요청 데이터 설정\n",
    "#         payload = {\n",
    "#             \"version\": \"V2\",\n",
    "#             \"requestId\": \"sample_id\",\n",
    "#             \"timestamp\": 123456789,\n",
    "#             \"images\": [{\n",
    "#                 \"format\": \"jpg\",\n",
    "#                 \"name\": \"ocr_test\",\n",
    "#                 \"data\": image_data,\n",
    "#                 \"enableTableDetection\": True,  # 표 감지 요청\n",
    "#                 \"detectOrientation\": True\n",
    "#             }]\n",
    "#         }\n",
    "\n",
    "#         # ✅ 네이버 OCR API 호출\n",
    "#         response = requests.post(CLOVA_OCR_URL, headers=HEADERS, data=json.dumps(payload))\n",
    "\n",
    "#         # ✅ 응답 상태 코드 확인\n",
    "#         if response.status_code != 200:\n",
    "#             print(f\"❌ 네이버 OCR API 오류: {response.text}\")\n",
    "#             return None\n",
    "\n",
    "#         # ✅ 응답을 JSON으로 변환\n",
    "#         result = response.json()\n",
    "\n",
    "#         # ✅ OCR 결과 추출 및 표 변환\n",
    "#         extracted_text = []\n",
    "#         if \"images\" in result:\n",
    "#             for image in result.get(\"images\", []):\n",
    "#                 for field in image.get(\"fields\", []):\n",
    "#                     extracted_text.append(field.get(\"inferText\", \"\"))\n",
    "\n",
    "#         # ✅ OCR 결과를 범용적인 표 데이터로 변환\n",
    "#         table_data = reconstruct_table_from_text(extracted_text)\n",
    "\n",
    "#         # ✅ JSON 형식으로 OCR 결과 저장\n",
    "#         base_name = os.path.basename(image_path).split('.')[0]\n",
    "#         os.makedirs(\"ocr_results\", exist_ok=True)\n",
    "#         json_file_path = os.path.join(\"ocr_results\", f\"{base_name}.json\")\n",
    "\n",
    "#         ocr_result = {\n",
    "#             \"text\": extracted_text,\n",
    "#             \"table\": table_data\n",
    "#         }\n",
    "\n",
    "#         with open(json_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#             json.dump(ocr_result, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "#         print(f\"📝 OCR JSON 결과 저장 완료: {json_file_path}\")\n",
    "\n",
    "#         return {\"json_file\": json_file_path, \"table_data\": table_data}\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"❌ 네이버 OCR 오류 발생: {e}\")\n",
    "#         return None\n",
    "\n",
    "\n",
    "# def reconstruct_table_from_text(text_blocks):\n",
    "#     \"\"\"OCR에서 추출된 텍스트를 분석하여 범용적인 표 형식으로 변환\"\"\"\n",
    "#     table_data = []\n",
    "#     row = []\n",
    "    \n",
    "#     for word in text_blocks:\n",
    "#         if word.isdigit():  # 숫자가 나오면 열이 끝났다고 가정\n",
    "#             row.append(word)\n",
    "#             table_data.append(row)\n",
    "#             row = []\n",
    "#         else:\n",
    "#             row.append(word)\n",
    "\n",
    "#     # 마지막 줄 추가 (혹시 빠진 경우)\n",
    "#     if row:\n",
    "#         table_data.append(row)\n",
    "\n",
    "#     return table_data\n",
    "\n",
    "\n",
    "# def format_table_for_openai(table_data):\n",
    "#     \"\"\"OpenAI가 표로 인식할 수 있도록 Markdown 형식으로 변환\"\"\"\n",
    "#     if not table_data:\n",
    "#         return \"⚠ 표 데이터를 찾을 수 없습니다.\"\n",
    "\n",
    "#     # 헤더와 구분선 생성\n",
    "#     header = \"| \" + \" | \".join(table_data[0]) + \" |\"\n",
    "#     separator = \"| \" + \" | \".join([\"---\"] * len(table_data[0])) + \" |\"\n",
    "\n",
    "#     markdown_table = [header, separator]\n",
    "\n",
    "#     # 데이터 행 추가\n",
    "#     for row in table_data[1:]:\n",
    "#         markdown_table.append(\"| \" + \" | \".join(row) + \" |\")\n",
    "\n",
    "#     return \"\\n\".join(markdown_table)\n",
    "\n",
    "# # 📌 예제 실행\n",
    "# if __name__ == \"__main__\":\n",
    "#     image_path = \"aasdaf.JPG\"\n",
    "#     result = clova_ocr(image_path)\n",
    "#     if result and \"table_data\" in result:\n",
    "#         markdown_table = format_table_for_openai(result[\"table_data\"])\n",
    "#         print(\"\\n📌 변환된 표 데이터 (Markdown 형식)\\n\")\n",
    "#         print(markdown_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upstage Console API 설정\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "UPLOAD_URL = os.getenv(\"UPLOAD_URL\")\n",
    "\n",
    "\n",
    "def process_ocr_to_html(image_path):\n",
    "    \"\"\"이미지를 OCR하여 HTML로 변환 후 저장 (중복 저장 문제 해결)\"\"\"\n",
    "\n",
    "    # 1️⃣ OCR 수행 (파일 업로드)\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        files = {\"document\": image_file}  # ✅ 'document' 키로 전송\n",
    "        headers = {\"Authorization\": f\"Bearer {API_KEY}\"}\n",
    "        data = {\"ocr\": \"force\", \"model\": \"document-parse\"}\n",
    "\n",
    "        response = requests.post(UPLOAD_URL, headers=headers, files=files, data=data)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(f\"❌ Error: {response.status_code}, {response.text}\")\n",
    "            return False\n",
    "\n",
    "        ocr_data = response.json()\n",
    "\n",
    "    # 2️⃣ HTML 변환\n",
    "    html_content = ocr_data.get(\"content\", {}).get(\"html\", \"\")\n",
    "\n",
    "    if not html_content:\n",
    "        print(\"⚠ OCR 결과가 없습니다! API 응답을 확인하세요.\")\n",
    "        return False\n",
    "\n",
    "    # 📂 저장 폴더 생성 (없으면 만들기)\n",
    "    os.makedirs(text_folder, exist_ok=True)\n",
    "\n",
    "    # 🔥 중복 방지를 위해 타임스탬프 기반 파일명 생성\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    file_name = f\"ocr_text_{timestamp}.html\"\n",
    "    output_path = os.path.join(text_folder, file_name)\n",
    "\n",
    "    # 3️⃣ HTML 저장\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(html_content)\n",
    "\n",
    "    print(f\"✅ HTML 파일이 성공적으로 저장되었습니다: {output_path}\")\n",
    "\n",
    "    os.remove(image_path)\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_and_delete_html_files(html_folder, output_file):\n",
    "    \"\"\"여러 개의 HTML 파일을 하나로 합친 후 기존 파일 삭제\"\"\"\n",
    "    with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        outfile.write(\"<!DOCTYPE html>\\n<html>\\n<head>\\n<meta charset='utf-8'>\\n<title>Merged HTML</title>\\n</head>\\n<body>\\n\")\n",
    "        \n",
    "        for file_name in sorted(os.listdir(html_folder)):  # 정렬된 순서로 파일 읽기\n",
    "            if file_name.endswith('.html'):  # .html 파일만 처리\n",
    "                file_path = os.path.join(html_folder, file_name)\n",
    "                with open(file_path, 'r', encoding='utf-8') as infile:\n",
    "                    outfile.write(infile.read())  # HTML 내용 추가\n",
    "                    outfile.write(\"\\n\")  # 파일 구분을 위한 줄바꿈 추가\n",
    "                print(f\"✅ 합침: {file_name}\")\n",
    "\n",
    "        outfile.write(\"\\n</body>\\n</html>\")  # HTML 태그 닫기\n",
    "\n",
    "    print(f\"🎉 모든 HTML 파일이 '{output_file}'로 합쳐졌습니다!\")\n",
    "\n",
    "    # ✅ 기존 HTML 파일 삭제\n",
    "    for file_name in os.listdir(html_folder):\n",
    "        if file_name.endswith('.html') and file_name != os.path.basename(output_file):\n",
    "            file_path = os.path.join(html_folder, file_name)\n",
    "            os.remove(file_path)  # 파일 삭제\n",
    "            print(f\"🗑 삭제 완료: {file_name}\")\n",
    "\n",
    "    print(\"🚀 기존 HTML 파일 삭제 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_html_to_markdown_table(html_content):\n",
    "    \"\"\"HTML에서 표를 Markdown 형식으로 변환하고, 태그 속성을 제거하여 순수 텍스트만 추출하는 함수\"\"\"\n",
    "    \n",
    "    # BeautifulSoup으로 HTML 파싱\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "    # ✅ <img> 태그의 alt 속성을 텍스트로 변환\n",
    "    for img in soup.find_all(\"img\"):\n",
    "        if img.has_attr(\"alt\"):\n",
    "            img.replace_with(img[\"alt\"])  # 이미지 태그를 alt 속성값으로 대체\n",
    "\n",
    "    # ✅ 모든 태그 속성 제거 (태그 자체는 유지)\n",
    "    for tag in soup.find_all(True):\n",
    "        tag.attrs = {}  # 속성 제거\n",
    "\n",
    "    # ✅ <table> 태그를 Markdown 표로 변환\n",
    "    for table in soup.find_all(\"table\"):\n",
    "        rows = []\n",
    "        headers = table.find_all(\"th\")  # 테이블 헤더 가져오기\n",
    "        if headers:\n",
    "            headers_text = [th.get_text(strip=True) for th in headers]\n",
    "            rows.append(\"| \" + \" | \".join(headers_text) + \" |\")  # Markdown 헤더 추가\n",
    "            rows.append(\"|\" + \"|\".join([\"-\" * len(h) for h in headers_text]) + \"|\")  # 구분선 추가\n",
    "\n",
    "        # 본문 데이터 처리\n",
    "        for tr in table.find_all(\"tr\"):\n",
    "            cols = [td.get_text(strip=True) for td in tr.find_all([\"td\", \"th\"])]\n",
    "            if cols:  # 빈 행이 아니면 추가\n",
    "                rows.append(\"| \" + \" | \".join(cols) + \" |\")\n",
    "\n",
    "        table_text = \"\\n\".join(rows)  # Markdown 형식으로 변환\n",
    "        table.replace_with(table_text)  # <table> 태그를 변환된 Markdown 텍스트로 대체\n",
    "\n",
    "    # ✅ 최종적으로 순수 텍스트만 추출\n",
    "    clean_text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 처리 중: download_images\\image_1.jpg\n",
      "✅ 분할된 이미지 저장 완료: cropped_images\\image_1_processed_crop_0.jpg\n",
      "📌 총 1개의 이미지로 분할 완료!\n",
      "✅ HTML 파일이 성공적으로 저장되었습니다: ocr_texts\\ocr_text_20250221_162052.html\n",
      "🚀 처리 중: download_images\\image_2.jpg\n",
      "✅ 분할된 이미지 저장 완료: cropped_images\\image_2_processed_crop_0.jpg\n",
      "📌 총 1개의 이미지로 분할 완료!\n",
      "✅ HTML 파일이 성공적으로 저장되었습니다: ocr_texts\\ocr_text_20250221_162053.html\n",
      "🚀 처리 중: download_images\\image_3.jpg\n",
      "✅ 분할된 이미지 저장 완료: cropped_images\\image_3_processed_crop_0.jpg\n",
      "✅ 분할된 이미지 저장 완료: cropped_images\\image_3_processed_crop_1.jpg\n",
      "✅ 분할된 이미지 저장 완료: cropped_images\\image_3_processed_crop_2.jpg\n",
      "📌 총 3개의 이미지로 분할 완료!\n",
      "✅ HTML 파일이 성공적으로 저장되었습니다: ocr_texts\\ocr_text_20250221_162055.html\n",
      "✅ HTML 파일이 성공적으로 저장되었습니다: ocr_texts\\ocr_text_20250221_162057.html\n",
      "✅ HTML 파일이 성공적으로 저장되었습니다: ocr_texts\\ocr_text_20250221_162058.html\n",
      "🚀 처리 중: download_images\\image_4.png\n",
      "✅ 분할된 이미지 저장 완료: cropped_images\\image_4_processed_crop_0.jpg\n",
      "📌 총 1개의 이미지로 분할 완료!\n",
      "✅ HTML 파일이 성공적으로 저장되었습니다: ocr_texts\\ocr_text_20250221_162100.html\n",
      "🎉 모든 이미지 처리 완료!\n"
     ]
    }
   ],
   "source": [
    "# ✅ OCR 실행할 이미지 리스트 (이미 다운로드된 이미지 목록 가져오기)\n",
    "image_files = [os.path.join(save_folder, img) for img in os.listdir(save_folder) if img.endswith((\".jpg\", \".png\", \".jpeg\"))]\n",
    "\n",
    "\n",
    "for image_path in image_files:\n",
    "    print(f\"🚀 처리 중: {image_path}\")\n",
    "\n",
    "    # 1️⃣ 이미지 전처리\n",
    "    processed_image = preprocess_image(image_path)\n",
    "    if processed_image is None:\n",
    "        continue  # 전처리 실패 시 건너뜀\n",
    "\n",
    "    # 2️⃣ 전처리된 이미지 분할\n",
    "    cropped_images = split_vertical_with_overlap(processed_image, cropped_folder)\n",
    "\n",
    "    # 3️⃣ OCR 수행\n",
    "    for cropped_image in cropped_images:\n",
    "        # perform_ocr_and_save(cropped_image)\n",
    "        process_ocr_to_html(cropped_image)\n",
    "\n",
    "print(\"🎉 모든 이미지 처리 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 정리된 HTML 저장 완료: ocr_texts\\ocr_text_20250221_162052.html\n",
      "✅ 정리된 HTML 저장 완료: ocr_texts\\ocr_text_20250221_162053.html\n",
      "✅ 정리된 HTML 저장 완료: ocr_texts\\ocr_text_20250221_162055.html\n",
      "✅ 정리된 HTML 저장 완료: ocr_texts\\ocr_text_20250221_162057.html\n",
      "✅ 정리된 HTML 저장 완료: ocr_texts\\ocr_text_20250221_162058.html\n",
      "✅ 정리된 HTML 저장 완료: ocr_texts\\ocr_text_20250221_162100.html\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(text_folder):\n",
    "        if filename.endswith(\".html\"):  # HTML 파일만 처리\n",
    "            input_path = os.path.join(text_folder, filename)\n",
    "            output_path = os.path.join(text_folder, filename)\n",
    "\n",
    "            try:\n",
    "                # ✅ 원본 HTML 파일 읽기\n",
    "                with open(input_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                    html_data = file.read()\n",
    "\n",
    "                # ✅ HTML 정리 함수 실행\n",
    "                cleaned_html = clean_html_to_markdown_table(html_data)\n",
    "\n",
    "                # ✅ 정리된 HTML 저장\n",
    "                with open(output_path, \"w\", encoding=\"utf-8\") as file:\n",
    "                    file.write(cleaned_html)\n",
    "\n",
    "                print(f\"✅ 정리된 HTML 저장 완료: {output_path}\")\n",
    "\n",
    "            except FileNotFoundError:\n",
    "                print(f\"❌ 파일을 찾을 수 없습니다: {input_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ OpenAI API 키가 정상적으로 로드되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 환경 변수 가져오기\n",
    "client = openai.OpenAI(api_key = os.getenv(\"OPENAI_API_KEY\"))\n",
    "if client is None:\n",
    "    print(\"🚨 OpenAI API 키가 설정되지 않았습니다! .env 파일을 확인하세요.\")\n",
    "else:\n",
    "    print(\"✅ OpenAI API 키가 정상적으로 로드되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_text_with_openai(input_text):\n",
    "    \"\"\"📌 OpenAI API (최신 버전)로 RAG 기반 검색 최적화 문서 정리\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \n",
    "                 \"content\": \n",
    "                 \"\"\"\n",
    "                 이 문서는 RAG 기반 검색 데이터로 사용할 것입니다.\n",
    "                 따라서 검색 최적화를 위해 다음과 같이 정리해 주세요.\n",
    "\n",
    "                 1. **문서의 원래 의미를 유지하면서 문장을 다듬어 가독성을 높이세요.**  \n",
    "                 2. **표(Table) 데이터는 원본 그대로 유지하세요.** (Markdown 표 `|` 형식 유지)  \n",
    "                 3. **불필요한 중복 문장 및 공백을 제거하세요.**  \n",
    "                 4. **문서의 계층 구조(제목, 소제목)를 유지하여 쉽게 검색할 수 있도록 하세요.**   \n",
    "                 5. **필요한 경우, 목록(Bullet Point)을 활용하여 가독성을 높이세요.**  \n",
    "                 6. **의미를 바꾸지 않도록 주의하고, 정보가 빠지지 않도록 유지하세요.**  \n",
    "                 \"\"\"\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": input_text}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # ✅ 최신 OpenAI SDK에서는 응답 데이터 접근 방식 변경됨\n",
    "        corrected_text = response.choices[0].message.content\n",
    "\n",
    "        return corrected_text\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ OpenAI API 오류 발생: {e}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text_file(input_folder, output_folder):\n",
    "    \"\"\"OCR 결과 파일을 읽고 OpenAI로 수정한 후 별도 저장\"\"\"\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".html\"):  # HTML 파일만 처리\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "            output_path = os.path.join(output_folder, filename)\n",
    "\n",
    "            try:\n",
    "                with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    ocr_text = f.read()\n",
    "\n",
    "                print(f\"🚀 OpenAI에 텍스트 전달 중... (파일: {input_path})\")\n",
    "                corrected_text = correct_text_with_openai(ocr_text)\n",
    "\n",
    "                if corrected_text:\n",
    "                    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                        f.write(corrected_text)\n",
    "                    print(f\"✅ 수정된 텍스트 저장 완료: {output_path}\")\n",
    "                else:\n",
    "                    print(f\"⚠️ {filename} 처리 실패: OpenAI 응답 없음\")\n",
    "                    \n",
    "            except FileNotFoundError:\n",
    "                print(f\"❌ 파일을 찾을 수 없습니다: {input_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 OpenAI에 텍스트 전달 중... (파일: ocr_texts\\ocr_text_20250221_162052.html)\n",
      "✅ 수정된 텍스트 저장 완료: ocr_texts\\ocr_text_20250221_162052.html\n",
      "🚀 OpenAI에 텍스트 전달 중... (파일: ocr_texts\\ocr_text_20250221_162053.html)\n",
      "✅ 수정된 텍스트 저장 완료: ocr_texts\\ocr_text_20250221_162053.html\n",
      "🚀 OpenAI에 텍스트 전달 중... (파일: ocr_texts\\ocr_text_20250221_162055.html)\n",
      "✅ 수정된 텍스트 저장 완료: ocr_texts\\ocr_text_20250221_162055.html\n",
      "🚀 OpenAI에 텍스트 전달 중... (파일: ocr_texts\\ocr_text_20250221_162057.html)\n",
      "✅ 수정된 텍스트 저장 완료: ocr_texts\\ocr_text_20250221_162057.html\n",
      "🚀 OpenAI에 텍스트 전달 중... (파일: ocr_texts\\ocr_text_20250221_162058.html)\n",
      "✅ 수정된 텍스트 저장 완료: ocr_texts\\ocr_text_20250221_162058.html\n",
      "🚀 OpenAI에 텍스트 전달 중... (파일: ocr_texts\\ocr_text_20250221_162100.html)\n",
      "✅ 수정된 텍스트 저장 완료: ocr_texts\\ocr_text_20250221_162100.html\n"
     ]
    }
   ],
   "source": [
    "process_text_file(text_folder, text_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ✅ 사용 예시 (폴더 경로 설정)\n",
    "# output_file = os.path.join(text_folder, \"merged_text.html\")  # 최종 합쳐질 파일 경로\n",
    "\n",
    "# merge_and_delete_html_files(text_folder, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
